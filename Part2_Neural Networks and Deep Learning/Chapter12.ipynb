{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CHAPTER 12**\n",
        "# **Custom Models and Training with TensorFlow**\n",
        "\n",
        "**A Quick Tour of TensorFlow**\n",
        "This subchapter introduces TensorFlow as a comprehensive framework for building, training, and deploying machine learning models. TensorFlow provides low-level operations as well as high-level APIs such as Keras. The chapter emphasizes that TensorFlow is not only a neural network library but also a general numerical computation platform optimized for performance and scalability.\n",
        "TensorFlow operations work on tensors, which are multidimensional arrays similar to NumPy arrays but with additional features such as GPU acceleration and automatic differentiation.\n"
      ],
      "metadata": {
        "id": "ZBb6JmNMyejq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using TensorFlow like NumPy**\n",
        "\n",
        "This section explains that TensorFlow tensors behave similarly to NumPy arrays. They support indexing, slicing, reshaping, and broadcasting. However, tensors are immutable, meaning their values cannot be changed directly.\n",
        "Conversion between NumPy arrays and TensorFlow tensors is straightforward, allowing easy integration with existing NumPy-based workflows.\n"
      ],
      "metadata": {
        "id": "taTOr3aHytLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Membuat matrix 2x3\n",
        "matrix = tf.constant([[1., 2., 3.],\n",
        "                      [4., 5., 6.]])\n",
        "print(matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_XbPCJcyzXe",
        "outputId": "42a0d573-6048-4506-a5ea-05c211992aaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(42) # scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzmOmt2oy-2F",
        "outputId": "3ae5e368-137c-4a3a-c44e-184aa513e0a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U1Y-8cBy1BF",
        "outputId": "af2f1fbd-85b0-4c20-c720-a9ea6989ab07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-p-SdlpzIyb",
        "outputId": "16ef6570-0e4c-44bb-cb93-6c003808016c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[:, 1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCNHKsIGzKaB",
        "outputId": "224cbc48-138b-4324-86f7-226de88d2b56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 3.],\n",
              "       [5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[..., 1, tf.newaxis]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRf68JolzNH_",
        "outputId": "9c7cc70c-dbd8-4aec-861b-0b5fee7dc859"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[2.],\n",
              "       [5.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7wqZ3P-zPY_",
        "outputId": "acfb9313-5549-4c0c-9d56-a8ea436a4e21"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[11., 12., 13.],\n",
              "       [14., 15., 16.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.square(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z1NvRvDzRcG",
        "outputId": "81401b39-29ba-4633-97ee-074b381222ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t @ tf.transpose(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKH-LbCszW8Z",
        "outputId": "beb35360-d95c-42f8-fa1b-2822fc6f885a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[14., 32.],\n",
              "       [32., 77.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Buat array NumPy\n",
        "a = np.array([2., 4., 5.])\n",
        "\n",
        "# Ubah menjadi tensor TensorFlow\n",
        "tensor_a = tf.constant(a)\n",
        "print(tensor_a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZUAo3RozeGA",
        "outputId": "c04f6779-a03e-4523-ca7f-9451971ae0db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2. 4. 5.], shape=(3,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.numpy() # or np.array(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2V3KTBgzqoL",
        "outputId": "831fbff9-5e88-4deb-849a-80159ceb5179"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.square(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cz8bFNWzrfI",
        "outputId": "3031eeb4-2f77-48c5-e273-d394317115a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.square(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDMF8RA9ztBq",
        "outputId": "91db022a-2831-4416-b289-9388f2465b09"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.constant(2., dtype=tf.float32) + tf.constant(40., dtype=tf.float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5l8-k0Qz035",
        "outputId": "9d2bd85a-0f18-43e9-8744-8a679a0c0f03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Pilih float32\n",
        "result = tf.constant(2., dtype=tf.float32) + tf.constant(40., dtype=tf.float32)\n",
        "print(result)  # 42.0, dtype=float32\n",
        "\n",
        "# Atau pilih float64\n",
        "result = tf.constant(2., dtype=tf.float64) + tf.constant(40., dtype=tf.float64)\n",
        "print(result)  # 42.0, dtype=float64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiKfPLBAz_w_",
        "outputId": "f3156330-a847-4d32-9796-e4bc83a02b50"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(42.0, shape=(), dtype=float32)\n",
            "tf.Tensor(42.0, shape=(), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = tf.constant(40., dtype=tf.float64)\n",
        "tf.constant(2.0) + tf.cast(t2, tf.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M2V5s2z0GcV",
        "outputId": "9398cfb6-8527-4cb1-be3b-48f3e5f82c35"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEojfsJp0Jh5",
        "outputId": "0342d716-774a-4d7f-d54e-e853c5fa85c0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.assign(2 * v) # => [[2., 4., 6.], [8., 10., 12.]]\n",
        "v[0, 1].assign(42) # => [[2., 42., 6.], [8., 10., 12.]]\n",
        "v[:, 2].assign([0., 1.]) # => [[2., 42., 0.], [8., 10., 1.]]\n",
        "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])\n",
        "# => [[100., 42., 0.], [8., 10., 200.]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AErhgdzU0NY2",
        "outputId": "231cc539-53a4-45ad-8449-be67e181256d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[100.,  42.,   0.],\n",
              "       [  8.,  10., 200.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Loss Functions**\n",
        "\n",
        "This subchapter explains situations where built-in loss functions are insufficient. TensorFlow allows users to define custom loss functions using Python functions that operate on tensors.\n",
        "Custom loss functions must:\n",
        "•\tTake y_true and y_pred as inputs\n",
        "•\tReturn a scalar tensor\n"
      ],
      "metadata": {
        "id": "HYw2ORcq0QdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "metadata": {
        "id": "1Uc6i2qY0V-I"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data      # fitur, shape (150, 4)\n",
        "y = iris.target    # label, shape (150,)\n",
        "\n",
        "# 2. Split dataset menjadi train dan test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # fit pada data training\n",
        "X_test_scaled  = scaler.transform(X_test)       # transform data test\n"
      ],
      "metadata": {
        "id": "s6lmGVhU01wE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving and Loading Models That Contain Custom Components**\n",
        "\n",
        "Models that use custom loss functions or layers require special handling when saving and loading. TensorFlow allows custom objects to be passed explicitly during model loading.\n"
      ],
      "metadata": {
        "id": "wS-6LWMB1Nur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def create_huber(threshold=1.0):\n",
        "    def huber_fn(y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    return huber_fn\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(32, activation=\"relu\", input_shape=(4,)),  # ganti 4 sesuai jumlah fitur\n",
        "    keras.layers.Dense(16, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)  # regresi\n",
        "])\n",
        "\n",
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\")\n",
        "\n",
        "import numpy as np\n",
        "X_train = np.random.rand(100, 4)\n",
        "y_train = np.random.rand(100, 1)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqwV9JYD1tQY",
        "outputId": "8762f633-8f6d-4111-bbcd-8d34560c2d5a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.2460\n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2005\n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1613\n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1314\n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1073 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c00f3417ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class HuberLoss(keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n"
      ],
      "metadata": {
        "id": "KuPmHo2z2Mae"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Activation Functions, Initializers, Regularizers, and Constraints**\n",
        "\n",
        "TensorFlow allows customization of many internal components of neural networks. Users can define custom activation functions, weight initializers, regularizers, and constraints as simple functions.\n"
      ],
      "metadata": {
        "id": "I-XRUL3Y2Qa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def my_softplus(z):\n",
        "    \"\"\"Custom softplus activation function.\"\"\"\n",
        "    return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    \"\"\"Custom Glorot/Xavier initializer.\"\"\"\n",
        "    stddev = tf.sqrt(2.0 / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_l1_regularizer(weights):\n",
        "    \"\"\"Custom L1 regularization with coefficient 0.01.\"\"\"\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "def my_positive_weights(weights):\n",
        "    \"\"\"Ensure weights are non-negative.\"\"\"\n",
        "    return tf.where(weights < 0.0, tf.zeros_like(weights), weights)\n"
      ],
      "metadata": {
        "id": "_PZeD8ww2Sjh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(30, activation=my_softplus,\n",
        "kernel_initializer=my_glorot_initializer,\n",
        "kernel_regularizer=my_l1_regularizer,\n",
        "kernel_constraint=my_positive_weights)"
      ],
      "metadata": {
        "id": "_AxNzt4_2aIK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
        "    \"\"\"Custom L1 regularizer with adjustable factor.\"\"\"\n",
        "\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, weights):\n",
        "        \"\"\"Compute L1 regularization penalty.\"\"\"\n",
        "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Return config for serialization.\"\"\"\n",
        "        return {\"factor\": self.factor}\n"
      ],
      "metadata": {
        "id": "oa22qqIi2dts"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Metrics**\n",
        "\n",
        "Metrics differ from loss functions in that they are used only for evaluation, not optimization. TensorFlow allows users to define custom metrics using stateful objects.\n"
      ],
      "metadata": {
        "id": "jLU8xWjB2n3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
      ],
      "metadata": {
        "id": "HybFRo2Q2rLs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = keras.metrics.Precision()\n",
        "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrUsxjTJ2tuN",
        "outputId": "b8a21bfb-ed01-45ba-f038-f2158ba31778"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.800000011920929>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojoXV0kN2yZd",
        "outputId": "eea83cd0-f737-4a37-87b1-bb13ed5ec760"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision.result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwmrZz9u22g1",
        "outputId": "771522f4-a573-4957-ef6b-d0c965bbc776"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision.variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oJAq8ib24SA",
        "outputId": "e9b1e34e-a06c-4b6b-9bc6-876e2306bef6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[4.]>,\n",
              " <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[4.]>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HuberMetric(keras.metrics.Metric):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)  # handles base args (e.g., dtype)\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        self.total.assign_add(tf.reduce_sum(metric))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n"
      ],
      "metadata": {
        "id": "cfQU_r6T26RA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Layers**\n",
        "\n",
        "This section explains how to create custom layers by subclassing keras.layers.Layer. Custom layers allow full control over forward computation and trainable parameters.\n"
      ],
      "metadata": {
        "id": "D6BdH6c23ROb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
      ],
      "metadata": {
        "id": "rFPXZ_km3Te7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDense(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\",\n",
        "            shape=[batch_input_shape[-1], self.units],\n",
        "            initializer=\"glorot_normal\"\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\",\n",
        "            shape=[self.units],\n",
        "            initializer=\"zeros\"\n",
        "        )\n",
        "        super().build(batch_input_shape)  # must be at the end\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.activation(X @ self.kernel + self.bias)\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"units\": self.units,\n",
        "            \"activation\": keras.activations.serialize(self.activation)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "BOvR0Sy23VS6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMultiLayer(keras.layers.Layer):\n",
        "    def call(self, X):\n",
        "        X1, X2 = X\n",
        "        return [X1 + X2, X1 * X2, X1 / X2]\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        b1, b2 = batch_input_shape\n",
        "        # Mengembalikan daftar TensorShape untuk tiap output\n",
        "        return [b1, b1, b1]  # catatan: ini sederhana, sebaiknya menyesuaikan broadcasting rules\n"
      ],
      "metadata": {
        "id": "ideMKMj33gpB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGaussianNoise(keras.layers.Layer):\n",
        "    def __init__(self, stddev, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, X, training=None):\n",
        "        if training:\n",
        "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "            return X + noise\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return batch_input_shape\n"
      ],
      "metadata": {
        "id": "hSEyrXeI3rkB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Models**\n",
        "\n",
        "Custom models provide full flexibility by subclassing keras.models.Model. This approach is useful for complex architectures that cannot be expressed using Sequential or Functional APIs.\n"
      ],
      "metadata": {
        "id": "yv1ftvRB3vtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [\n",
        "            keras.layers.Dense(\n",
        "                n_neurons,\n",
        "                activation=\"elu\",\n",
        "                kernel_initializer=\"he_normal\"\n",
        "            ) for _ in range(n_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return inputs + Z\n"
      ],
      "metadata": {
        "id": "4ZnnDdUK3w-L"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualRegressor(keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(\n",
        "            30,\n",
        "            activation=\"elu\",\n",
        "            kernel_initializer=\"he_normal\"\n",
        "        )\n",
        "        self.block1 = ResidualBlock(2, 30)\n",
        "        self.block2 = ResidualBlock(2, 30)\n",
        "        self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        # menerapkan block residual beberapa kali\n",
        "        for _ in range(1 + 3):\n",
        "            Z = self.block1(Z)\n",
        "            Z = self.block2(Z)\n",
        "        return self.out(Z)\n"
      ],
      "metadata": {
        "id": "ZdKVBSTm37Yf"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Losses and Metrics Based on Model Internals**\n",
        "\n",
        "When a model has multiple Internals, each output can have its own loss function and metrics. This allows different objectives to be optimized simultaneously.\n"
      ],
      "metadata": {
        "id": "eSjW4bZa4B2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReconstructingRegressor(keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [\n",
        "            keras.layers.Dense(\n",
        "                30,\n",
        "                activation=\"selu\",\n",
        "                kernel_initializer=\"lecun_normal\"\n",
        "            )\n",
        "            for _ in range(5)\n",
        "        ]\n",
        "        self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        n_inputs = batch_input_shape[-1]\n",
        "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        reconstruction = self.reconstruct(Z)\n",
        "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "        self.add_loss(0.05 * recon_loss)\n",
        "        return self.out(Z)\n"
      ],
      "metadata": {
        "id": "INlVWn844Jth"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Training Loops**\n",
        "\n",
        "This subchapter introduces custom training loops using tf.GradientTape. Custom loops provide maximum flexibility for research and experimentation.\n"
      ],
      "metadata": {
        "id": "UV8_cWnR4Vvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l2_reg = keras.regularizers.l2(0.05)\n",
        "model = keras.models.Sequential([\n",
        "keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
        "kernel_regularizer=l2_reg),\n",
        "keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])"
      ],
      "metadata": {
        "id": "FNnbv1i94bP7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "    idx = np.random.randint(len(X), size=batch_size)\n",
        "    return X[idx], y[idx]"
      ],
      "metadata": {
        "id": "5cKXPQLE4cRJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "    metrics_str = \" - \".join(\n",
        "        [\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])]\n",
        "    )\n",
        "    end = \"\" if iteration < total else \"\\n\"\n",
        "    print(\"\\r{}/{} - \".format(iteration, total) + metrics_str, end=end)\n"
      ],
      "metadata": {
        "id": "4fnBVJFU4fze"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=0.01)  # gunakan learning_rate\n",
        "loss_fn = keras.losses.MeanSquaredError()               # gunakan instance loss\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.MeanAbsoluteError()]\n"
      ],
      "metadata": {
        "id": "IIoKTG_h5DO6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "    idx = np.random.choice(len(X), size=batch_size, replace=True)\n",
        "    return X[idx], y[idx]\n"
      ],
      "metadata": {
        "id": "QJjZ-q3k5UnP"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "Chapter 12 emphasizes flexibility and control in TensorFlow:\n",
        "•\tCustom losses, metrics, layers, and models\n",
        "•\tAdvanced training workflows\n",
        "•\tLow-level and high-level API integration\n",
        "This chapter prepares readers to build highly customized and production-ready deep learning systems.\n"
      ],
      "metadata": {
        "id": "PmCQ1FIq5iCM"
      }
    }
  ]
}