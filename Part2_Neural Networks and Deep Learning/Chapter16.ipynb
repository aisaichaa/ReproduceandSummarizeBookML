{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CHAPTER 16**\n",
        "# **Natural Language Processing with RNNs and Attention**\n",
        "\n",
        "**Generating Text Using Character RNNs**\n",
        "\n",
        "This subchapter introduces the concept of generating text by training a Recurrent Neural Network (RNN) at the character level. Instead of predicting whole words, the model predicts the next character in a sequence, allowing it to learn spelling, punctuation, and writing style directly from raw text data.\n",
        "The process begins by loading a text corpus and converting it into a numerical representation. Each character is mapped to an integer ID, enabling the neural network to process the data. The training sequences are built using sliding windows, where each input sequence predicts the next character in the text. This approach allows the model to learn sequential dependencies over time.\n",
        "The RNN architecture is typically built using stacked LSTM layers followed by a dense output layer with softmax activation. During training, the model minimizes categorical cross-entropy loss, gradually learning to generate coherent sequences. Once trained, the model can generate new text by repeatedly sampling predicted probabilities and feeding the output back as input.\n"
      ],
      "metadata": {
        "id": "UANmd8KAItN_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ifFDD2aXIqvk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = keras.utils.get_file(\n",
        "    \"shakespeare.txt\",\n",
        "    \"https://homl.info/shakespeare\"\n",
        ")\n",
        "with open(filepath, \"r\") as f:\n",
        "    shakespeare_text = f.read()"
      ],
      "metadata": {
        "id": "3mlZVduQM1t5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(shakespeare_text)\n",
        "max_id = len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "h0du6BZVM345"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
        "encoded = encoded.flatten()"
      ],
      "metadata": {
        "id": "hbBTeCEcM6cj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(encoded)\n",
        "train_size = int(dataset_size * 0.1)  # bisa ganti 0.9 untuk full data\n",
        "train_data = encoded[:train_size]"
      ],
      "metadata": {
        "id": "8t-j9PQwM8s5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 50\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "AvZqOgV5NAJm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "\n",
        "train_generator = TimeseriesGenerator(\n",
        "    train_data, train_data, length=n_steps, batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "uE53b4s2NBLx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(max_id, 16),\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.LSTM(128),  # return_sequences=False\n",
        "    keras.layers.Dense(max_id, activation=\"softmax\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "jNq7bAhONDaD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "tv3rcqGxNFro"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stateful RNNs**\n",
        "\n",
        "This section explains stateful RNNs, which differ from stateless RNNs by preserving hidden states across batches. This is particularly useful when modeling very long sequences that cannot fit into memory at once.\n",
        "Instead of resetting the hidden state at each batch, a stateful RNN carries information forward, allowing it to maintain long-term context across batch boundaries. However, this approach requires careful batch alignment and manual resetting of states between epochs.\n",
        "Stateful RNNs are useful in streaming text generation and continuous sequence modeling but are more complex to manage compared to stateless models.\n"
      ],
      "metadata": {
        "id": "_z3iMhCvJCaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "n_steps = 100"
      ],
      "metadata": {
        "id": "HNNyHo_cJcLU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.layers.Input(batch_shape=(batch_size, n_steps))"
      ],
      "metadata": {
        "id": "Q8gWa04zV__M"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = keras.layers.Embedding(input_dim=max_id, output_dim=16)(inputs)"
      ],
      "metadata": {
        "id": "KClD1yEjWCOq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = keras.layers.LSTM(128, return_sequences=True, stateful=True)(x)\n",
        "x = keras.layers.LSTM(128, return_sequences=True, stateful=True)(x)"
      ],
      "metadata": {
        "id": "yjHKd89fWD_y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = keras.layers.Dense(max_id, activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "IkM-LEgBWGHL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "0MUNW8fgWH6I",
        "outputId": "65b8aefd-cb70-4058-b2da-2c560f79207e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │           \u001b[38;5;34m624\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m74,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m39\u001b[0m)          │         \u001b[38;5;34m5,031\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m211,479\u001b[0m (826.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,479</span> (826.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m211,479\u001b[0m (826.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,479</span> (826.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis**\n",
        "\n",
        "This subchapter introduces sentiment analysis, a fundamental NLP task where the goal is to classify text based on emotional polarity (e.g., positive or negative). The IMDB movie reviews dataset is used as a benchmark.\n",
        "The text data is preprocessed by converting words into integer sequences using a predefined vocabulary size. The model architecture consists of an embedding layer followed by LSTM layers and a sigmoid output for binary classification.\n",
        "Sentiment analysis demonstrates how RNNs can extract semantic meaning from text sequences and learn contextual word representations.\n"
      ],
      "metadata": {
        "id": "DvwX5m0XJh2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "VY7nNqkJJm0v"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "maxlen = 200  # maksimal panjang sequence\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen, padding='post', truncating='post')\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(input_dim=vocab_size, output_dim=16, input_length=maxlen),\n",
        "    keras.layers.LSTM(32),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "PheTsB7ZW7gf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBQcnjbbXGHL",
        "outputId": "4e5ebcf9-9a9a-4e2b-c855-1a36dbd4bad5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.5124 - loss: 0.6922\n",
            "Test Accuracy: 0.513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Masking**\n",
        "\n",
        "Masking is introduced to handle variable-length sequences. Since sequences are padded to a fixed length, padding tokens must be ignored during training to prevent them from influencing the model.\n",
        "Keras provides built-in masking support via the Embedding layer using mask_zero=True. This ensures that padded values do not affect the learning process.\n"
      ],
      "metadata": {
        "id": "Jo1yuejFJrhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, 16, mask_zero=True),\n",
        "    keras.layers.LSTM(32),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "LbutRDVPJvB-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reusing Pretrained Embeddings**\n",
        "\n",
        "This section discusses leveraging pretrained word embeddings such as GloVe to improve model performance and reduce training time. Instead of learning embeddings from scratch, pretrained vectors provide rich semantic representations learned from massive corpora.\n",
        "The embeddings are loaded and injected into the embedding layer, which can be frozen or fine-tuned during training.\n"
      ],
      "metadata": {
        "id": "RTOjeRkNJwvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# URL file GloVe 100d\n",
        "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_zip = \"glove.6B.zip\"\n",
        "\n",
        "# Download jika belum ada\n",
        "if not os.path.exists(glove_zip):\n",
        "    print(\"Downloading GloVe embeddings...\")\n",
        "    urllib.request.urlretrieve(url, glove_zip)\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "# Extract file yang diperlukan\n",
        "with zipfile.ZipFile(glove_zip, 'r') as zip_ref:\n",
        "    zip_ref.extract(\"glove.6B.100d.txt\", \".\")\n",
        "    print(\"Extraction complete!\")\n",
        "\n",
        "# Sekarang file glove.6B.100d.txt ada di direktori saat ini\n",
        "glove_path = \"glove.6B.100d.txt\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAuZhH0JY0OT",
        "outputId": "65001335-a58e-443f-9c02-81863be2a35a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GloVe embeddings...\n",
            "Download complete!\n",
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "t44pAwOiJ1AP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # jumlah kata teratas yang dipakai\n",
        "maxlen = 200        # panjang maksimal sequence\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen, padding=\"post\")\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen, padding=\"post\")"
      ],
      "metadata": {
        "id": "qbYXcfdSYfJY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100  # sesuai file GloVe yang dipakai\n",
        "embeddings_index = {}\n",
        "glove_path = \"glove.6B.100d.txt\"  # pastikan file sudah di-download\n",
        "\n",
        "with open(glove_path, encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.array(values[1:], dtype=\"float32\")\n",
        "        embeddings_index[word] = vector\n",
        "\n",
        "print(f\"Loaded {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cl-i3J3Xn6y",
        "outputId": "ccccd437-dad5-419f-8cbf-9f975d64495e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()  # dict: kata -> indeks\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i < vocab_size:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsHQEIliZuV8",
        "outputId": "faaccd97-8bb1-49fc-e5d3-f9e02b2255fd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = keras.layers.Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=maxlen,\n",
        "    trainable=False\n",
        ")"
      ],
      "metadata": {
        "id": "BOK9ruHYYmE6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    embedding_layer,\n",
        "    keras.layers.LSTM(128, return_sequences=False),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "2JqYS_IjZzxP"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObQ5lw_LZ6PG",
        "outputId": "09f4416a-d06d-4ead-c870-589e392fb318"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 93ms/step - accuracy: 0.5121 - loss: 0.6927\n",
            "Test accuracy: 0.5051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder Decoder Networks**\n",
        "\n",
        "This subchapter introduces sequence-to-sequence (seq2seq) models, commonly used in machine translation. The encoder processes the input sequence into a context vector, while the decoder generates the output sequence one token at a time.\n",
        "This architecture enables the transformation of variable-length input sequences into variable-length outputs, forming the basis for modern NLP systems.\n"
      ],
      "metadata": {
        "id": "SR4o-W4HJ6h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.layers.Input(shape=[None])\n",
        "encoder_embedding = keras.layers.Embedding(vocab_size, 16)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = keras.layers.LSTM(512, return_state=True)(\n",
        "    encoder_embedding\n",
        ")\n",
        "encoder_state = [state_h, state_c]\n"
      ],
      "metadata": {
        "id": "qjwH5tGJKBuf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Mechanisms**\n",
        "\n",
        "The final subchapter introduces attention, a mechanism that allows the decoder to focus on different parts of the input sequence during generation. Instead of relying on a single context vector, attention computes weighted combinations of encoder outputs.\n",
        "Attention significantly improves performance in long sequences and is a foundational idea behind Transformers.\n"
      ],
      "metadata": {
        "id": "gqpbHDHbKFJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "1BYyXXPCKH-r"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "timesteps_encoder = 10\n",
        "timesteps_decoder = 8\n",
        "input_dim = 20   # fitur per timestep input encoder\n",
        "output_dim = 15"
      ],
      "metadata": {
        "id": "B1Bx6UOxbQFb"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.random.rand(batch_size, timesteps_encoder, input_dim).astype(np.float32)\n",
        "decoder_input_data = np.random.rand(batch_size, timesteps_decoder, output_dim).astype(np.float32)\n",
        "decoder_target_data = np.random.randint(0, output_dim, size=(batch_size, timesteps_decoder))"
      ],
      "metadata": {
        "id": "fIr9A3vCbpgb"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.Input(shape=(None, input_dim))\n",
        "encoder_lstm = keras.layers.LSTM(128, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n"
      ],
      "metadata": {
        "id": "3hfar6f9bu4w"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = keras.Input(shape=(None, output_dim))\n",
        "decoder_lstm = keras.layers.LSTM(128, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)"
      ],
      "metadata": {
        "id": "Tt6KlLlrbzVL"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "attention_layer = keras.layers.Attention()\n",
        "attention_output = attention_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "# Gabungkan attention dengan decoder outputs\n",
        "decoder_combined = keras.layers.Concatenate()([decoder_outputs, attention_output])\n",
        "\n",
        "# Output layer\n",
        "decoder_dense = keras.layers.Dense(output_dim, activation='softmax')\n",
        "decoder_outputs_final = decoder_dense(decoder_combined)\n",
        "\n",
        "# Model\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs_final)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "# Coba fit dengan data dummy\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, epochs=1)"
      ],
      "metadata": {
        "id": "umkHe5PTb_e_",
        "outputId": "7e1cabe4-19cd-4572-fbc9-296339ee1c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │     \u001b[38;5;34m76,288\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │     \u001b[38;5;34m73,728\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lstm_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lstm_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)  │      \u001b[38;5;34m3,855\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">76,288</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m153,871\u001b[0m (601.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">153,871</span> (601.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m153,871\u001b[0m (601.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">153,871</span> (601.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 2.7262\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d0fd5becc80>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "Chapter 16 provides a comprehensive overview of NLP using RNNs, covering text generation, sentiment analysis, sequence modeling, pretrained embeddings, encoder–decoder architectures, and attention mechanisms. These concepts form the foundation for advanced NLP models and modern architectures such as Transformers.\n"
      ],
      "metadata": {
        "id": "NWYyweTaKKyJ"
      }
    }
  ]
}